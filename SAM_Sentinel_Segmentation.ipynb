{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56498757-0352-4191-9b06-25375ae14899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "import sys\n",
    "!\"{sys.executable}\" -m pip install opencv-python matplotlib\n",
    "!\"{sys.executable}\" -m pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "\n",
    "!mkdir images\n",
    "!curl -o images/truck.jpg https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n",
    "!curl -o images/groceries.jpg https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/groceries.jpg\n",
    "!curl -O https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aba8d5-de70-402b-a21a-b25792f39b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0fcdc-982e-4766-98e1-3c3d21101030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, box\n",
    "from rasterio.features import shapes\n",
    "import rasterio\n",
    "from rasterio.mask import mask as rio_mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import math\n",
    "\n",
    "# Paths to files\n",
    "tif_file = \"T34TCR_20230708T093549_TCI_10m.jp2\"             # Original satellite image\n",
    "mask_file = \"ParcelaMaska.tif\"        # Mask file with parcels\n",
    "sam_checkpoint = \"sam_vit_l_0b3195.pth\"  # SAM model\n",
    "\n",
    "#SAM parameters\n",
    "SAM_tile_size = 512\n",
    "SAM_overlap = 64\n",
    "SAM_points_per_slide = 16\n",
    "SAM_pred_iou_thresh = 0.9\n",
    "SAM_stability_score_thresh = 0.9\n",
    "output_file_name = \"overlap6.shp\"\n",
    "\n",
    "# Load SAM model\n",
    "model_type = \"vit_l\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "# Load image\n",
    "with rasterio.open(tif_file) as src_img:\n",
    "    image = src_img.read()\n",
    "    img_transform = src_img.transform\n",
    "    img_crs = src_img.crs\n",
    "    img_bounds = src_img.bounds\n",
    "    img_width = src_img.width\n",
    "    img_height = src_img.height\n",
    "\n",
    "# Load mask\n",
    "with rasterio.open(mask_file) as src_mask:\n",
    "    mask = src_mask.read(1)  # Assuming mask is in the first band\n",
    "    mask_transform = src_mask.transform\n",
    "    mask_crs = src_mask.crs\n",
    "    mask_bounds = src_mask.bounds\n",
    "\n",
    "# Reproject mask if CRS do not match\n",
    "if mask_crs != img_crs:\n",
    "    print(\"CRS do not match. Reprojecting mask to image CRS...\")\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src_mask.crs, img_crs, src_mask.width, src_mask.height, *src_mask.bounds)\n",
    "    mask_reprojected = np.zeros((height, width), dtype=mask.dtype)\n",
    "    reproject(\n",
    "        source=mask,\n",
    "        destination=mask_reprojected,\n",
    "        src_transform=mask_transform,\n",
    "        src_crs=mask_crs,\n",
    "        dst_transform=transform,\n",
    "        dst_crs=img_crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "    mask = mask_reprojected\n",
    "    mask_transform = transform\n",
    "else:\n",
    "    print(\"CRS are the same.\")\n",
    "\n",
    "# Crop mask to image area\n",
    "print(\"Cropping mask to image area...\")\n",
    "img_bbox = [box(*img_bounds)]\n",
    "img_geo = gpd.GeoDataFrame({'geometry': img_bbox}, crs=img_crs)\n",
    "\n",
    "with rasterio.open(mask_file) as src_mask:\n",
    "    mask_cropped, mask_cropped_transform = rio_mask(\n",
    "        src_mask, img_geo.geometry, crop=True, all_touched=True, nodata=0, filled=True\n",
    "    )\n",
    "\n",
    "mask = mask_cropped[0]  # Take the first (and only) layer\n",
    "mask_transform = mask_cropped_transform\n",
    "\n",
    "if (mask.shape[0] != img_height) or (mask.shape[1] != img_width):\n",
    "    print(\"Resampling mask to match image dimensions...\")\n",
    "    mask_resampled = np.zeros((img_height, img_width), dtype=mask.dtype)\n",
    "    reproject(\n",
    "        source=mask,\n",
    "        destination=mask_resampled,\n",
    "        src_transform=mask_transform,\n",
    "        src_crs=img_crs,\n",
    "        dst_transform=img_transform,\n",
    "        dst_crs=img_crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "    mask = mask_resampled\n",
    "else:\n",
    "    print(\"Mask and image dimensions are the same.\")\n",
    "\n",
    "# Ensure the mask is binary (0 and 1)\n",
    "mask_binary = (mask > 0).astype(np.uint8)\n",
    "\n",
    "# Prepare the image\n",
    "image = np.transpose(image, (1, 2, 0))\n",
    "if image.shape[2] > 3:\n",
    "    image = image[:, :, :3]\n",
    "\n",
    "if image.dtype != np.uint8:\n",
    "    image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "# Define tile parameters\n",
    "tile_size = SAM_tile_size  # Adjust as needed\n",
    "overlap = SAM_overlap     # Adjust as needed\n",
    "\n",
    "# Calculate the number of tiles\n",
    "tiles_x = math.ceil((img_width - overlap) / (tile_size - overlap))\n",
    "tiles_y = math.ceil((img_height - overlap) / (tile_size - overlap))\n",
    "\n",
    "# Initialize final mask\n",
    "final_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "# Process only the first few tiles\n",
    "max_tiles_to_process = 40 # Set the maximum number of tiles you want to process\n",
    "\n",
    "# Counter for processed tiles\n",
    "tiles_processed = 0\n",
    "\n",
    "# Process tiles\n",
    "for i in range(tiles_y):\n",
    "    for j in range(tiles_x):\n",
    "        if tiles_processed >= max_tiles_to_process:\n",
    "            break  # Exit the loop after processing the desired number of tiles\n",
    "            \n",
    "        # Calculate tile boundaries\n",
    "        x_start = j * (tile_size - overlap)\n",
    "        y_start = i * (tile_size - overlap)\n",
    "        x_end = min(x_start + tile_size, img_width)\n",
    "        y_end = min(y_start + tile_size, img_height)\n",
    "\n",
    "        x_start = max(x_end - tile_size, 0)\n",
    "        y_start = max(y_end - tile_size, 0)\n",
    "\n",
    "        # Extract tile\n",
    "        tile_image = image[y_start:y_end, x_start:x_end, :]\n",
    "        tile_mask = mask_binary[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Skip tile if mask is empty\n",
    "        if np.sum(tile_mask) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Apply mask to tile\n",
    "        masked_tile_image = tile_image.copy()\n",
    "        masked_tile_image[tile_mask == 0] = 0\n",
    "        \n",
    "        # Prepare tile for SAM\n",
    "        tile_image_rgb = masked_tile_image\n",
    "        if tile_image_rgb.dtype != np.uint8:\n",
    "            tile_image_rgb = ((tile_image_rgb - tile_image_rgb.min()) / (tile_image_rgb.max() - tile_image_rgb.min()) * 255).astype(np.uint8)\n",
    "\n",
    "        # Check if tile is not empty\n",
    "        if np.sum(tile_image_rgb) == 0:\n",
    "            continue\n",
    "\n",
    "        # Run SAM on the tile\n",
    "        mask_generator = SamAutomaticMaskGenerator(\n",
    "            sam,\n",
    "            points_per_side=SAM_points_per_slide,\n",
    "            pred_iou_thresh=SAM_pred_iou_thresh,\n",
    "            stability_score_thresh=SAM_stability_score_thresh,\n",
    "        )\n",
    "\n",
    "        print(f\"Processing tile at position ({i}, {j})\")\n",
    "        tile_masks = mask_generator.generate(tile_image_rgb)\n",
    "\n",
    "        # Combine masks from this tile\n",
    "        tile_combined_mask = np.zeros((tile_image_rgb.shape[0], tile_image_rgb.shape[1]), dtype=np.uint8)\n",
    "        for m in tile_masks:\n",
    "            tile_combined_mask = np.maximum(tile_combined_mask, m['segmentation'].astype(np.uint8))\n",
    "\n",
    "        # Place the tile mask into the final mask\n",
    "        final_mask[y_start:y_end, x_start:x_end] = np.maximum(final_mask[y_start:y_end, x_start:x_end], tile_combined_mask)\n",
    "\n",
    "        tiles_processed += 1\n",
    "\n",
    "    if tiles_processed >= max_tiles_to_process:\n",
    "        break  # Exit the outer loop as well\n",
    "\n",
    "# Visualize the partial segmentation\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.imshow(final_mask, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title(\"Partial Segmentation\")\n",
    "plt.show()\n",
    "\n",
    "# Convert final_mask to polygons\n",
    "geoms = []\n",
    "for geom, value in shapes(final_mask, mask=None, transform=img_transform):\n",
    "    if value == 1:\n",
    "        geoms.append({'geometry': shape(geom)})\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(geoms, crs=img_crs)\n",
    "\n",
    "# Save to Shapefile\n",
    "output_shapefile = output_file_name\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Partial segmentation results saved to {output_shapefile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0919c1d-9c8f-446f-b641-a573233fb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask as rio_mask\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Putanje do fajlova\n",
    "shp_file = \"celo4.shp\"  # shapefile sa parcelama segmentisanim SAM-om\n",
    "crop_mask_file = \"maskCrops.tif\"  # Maska klasa useva\n",
    "\n",
    "# U훾itaj shapefile\n",
    "gdf = gpd.read_file(shp_file)\n",
    "\n",
    "# U훾itaj masku useva\n",
    "crop_data = rasterio.open(crop_mask_file)\n",
    "crop_crs = crop_data.crs\n",
    "crop_transform = crop_data.transform\n",
    "crop_bounds = crop_data.bounds\n",
    "\n",
    "\n",
    "# Proveri CRS, ako se ne poklapaju, reprojektuj gdf na crop_crs\n",
    "if gdf.crs != crop_crs:\n",
    "    gdf = gdf.to_crs(crop_crs)\n",
    "\n",
    "major_classes = []\n",
    "\n",
    "for idx, row in gdf.iterrows():\n",
    "    geom = row['geometry']\n",
    "    \n",
    "    # Izre탑i crop masku prema poligonu\n",
    "    # polygons argument mora biti [geom,]\n",
    "    out_image, out_transform = rio_mask(crop_data, [geom], crop=True, nodata=255)\n",
    "    # out_image je 3D [bands, height, width], ovde je verovatno [1, h, w]\n",
    "    mask_array = out_image[0]  # pretpostavka da je samo jedan band\n",
    "    \n",
    "    # Izbaci vrednosti koje su nodata (ako ih ima)\n",
    "    # Pod pretpostavkom da je nodata 255 ili nesto slicno\n",
    "    # Pogledaj crop mask file i vidi koji je nodata\n",
    "    # Ako nodata nije definisana, a imas 20 ili 6 klasa, mozda nema nodata\n",
    "    # Ako ima nevalidnih vrednosti (npr. >20), izbaci ih\n",
    "    valid_pixels = mask_array[(mask_array >=0) & (mask_array <= 20)]  # pretpostavka da su klase 0 do 20\n",
    "\n",
    "    if len(valid_pixels) == 0:\n",
    "        # Ako nema validnih piksela, mozda stavi major_class=20 (neklasifikovano) ili ostavi np.nan\n",
    "        major_class = 20  \n",
    "    else:\n",
    "        # Nadji najcescu vrednost\n",
    "        vals, counts = np.unique(valid_pixels, return_counts=True)\n",
    "        major_class = vals[np.argmax(counts)]\n",
    "    \n",
    "    major_classes.append(major_class)\n",
    "\n",
    "# Dodaj kolonu u gdf\n",
    "gdf['major_class'] = major_classes\n",
    "\n",
    "# Snimi a탑urirani shapefile\n",
    "gdf.to_file(\"celo4_with_class.shp\")\n",
    "print(\"Added major_class to each polygon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
